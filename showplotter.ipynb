{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "[Imports](#Imports)\n",
    "\n",
    "[Playground](#Playground)\n",
    "\n",
    "[Spotify Functions](#Spotify-Functions)\n",
    "\n",
    "[Songkick Functions](#Songkick-Functions)\n",
    "\n",
    "[Analysis Functions](#Analysis-Functions)\n",
    "\n",
    "[Analysis](#Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "\n",
    "[Back to top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kalebtsegaye/miniconda3/envs/env1/lib/python3.7/site-packages/pysal/explore/segregation/network/network.py:16: UserWarning: You need pandana and urbanaccess to work with segregation's network module\n",
      "You can install them with  `pip install urbanaccess pandana` or `conda install -c udst pandana urbanaccess`\n",
      "  \"You need pandana and urbanaccess to work with segregation's network module\\n\"\n",
      "/Users/kalebtsegaye/miniconda3/envs/env1/lib/python3.7/site-packages/pysal/model/spvcm/abstracts.py:10: UserWarning: The `dill` module is required to use the sqlite backend fully.\n",
      "  from .sqlite import head_to_sql, start_sql\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             geometry                 name\n",
      "0   POLYGON ((-69.8822326660156 12.4111099243165, ...                Aruba\n",
      "1   (POLYGON ((-61.7388916015625 17.5405540466309,...  Antigua and Barbuda\n",
      "2   POLYGON ((61.2765579223633 35.6072463989258, 6...          Afghanistan\n",
      "3   POLYGON ((-5.15213489532459 30.1804695129396, ...              Algeria\n",
      "4   (POLYGON ((45.0258293151855 41.0305480957031, ...           Azerbaijan\n",
      "..                                                ...                  ...\n",
      "46  POLYGON ((-94.46169128436209 34.19676535931296...                   AR\n",
      "47  (POLYGON ((-93.70752428365972 30.2395783556275...                   LA\n",
      "48  (POLYGON ((-80.7856622716253 28.78519435427305...                   FL\n",
      "49  (POLYGON ((-88.49752727880752 48.1737953723300...                   MI\n",
      "50  (POLYGON ((-161.3337853466416 58.7332483821643...                   AK\n",
      "\n",
      "[302 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#import necessary libraries\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, LineString\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import re\n",
    "import spotipy\n",
    "import base64\n",
    "import teetool as tt\n",
    "from collections import Counter\n",
    "import libpysal\n",
    "from pysal.model import spreg\n",
    "from libpysal.weights import Queen, Rook, KNN, Kernel\n",
    "import pysal\n",
    "from pysal.explore import esda\n",
    "from pysal.viz.splot import esda as esdaplot\n",
    "import cenpy\n",
    "import datetime\n",
    "from datetime import date\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "from census import Census\n",
    "import censusgeocode\n",
    "import us\n",
    "import folium\n",
    "import statsmodels.formula.api as sm\n",
    "import numpy\n",
    "import statistics\n",
    "import itertools as it\n",
    "import math\n",
    "\n",
    "# various API keys, necessary actions before beginning\n",
    "api_key = \"fCnCRQ1S6LDAS7zQ\"\n",
    "client_id = 'f5a0fe76389c42c0b85c832f1de66cf7'\n",
    "client_secret = 'e9d4fc0874f345b2b636a6e307384bb7'\n",
    "census_key = '684a12c6b65d2fe14bdf6d8354da8fe3aff08d70'\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id, client_secret)\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n",
    "\n",
    "cen = Census(census_key)\n",
    "\n",
    "# creation of a shapefile with both countries and US states included\n",
    "world = gpd.read_file('Countries_WGS84/Countries_WGS84.shp') #open file\n",
    "states_shp = gpd.read_file('states_21basic/states.shp') #open file\n",
    "\n",
    "s2 = states_shp[['geometry', 'STATE_ABBR']]\n",
    "s2.columns = ['geometry', 'name']\n",
    "\n",
    "w2 = world[['geometry', 'CNTRY_NAME']]\n",
    "w2.columns = ['geometry', 'name']\n",
    "\n",
    "ws = w2.append(s2)\n",
    "\n",
    "print(ws)\n",
    "\n",
    "\n",
    "#maybe remove festivals - songkick\n",
    "# maybe market - spotify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground\n",
    "\n",
    "This was for testing certain functions.\n",
    "\n",
    "[Back to top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spotify Functions\n",
    "\n",
    "[Back to top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# spotify function definitions\n",
    "\n",
    "# given a name/id or genre, will provide a list of \n",
    "# artists that exist in relation and also are within the follower limit\n",
    "\n",
    "# custom function used to sort by num of shared genres\n",
    "def custom_sort(x):\n",
    "    return x[2]\n",
    "\n",
    "query_count = 0\n",
    "\n",
    "# handles counting the genres for related artists\n",
    "def ra_help(artid, genres, followers, lessthan):\n",
    "    global query_count # count of the amount of spotify queries made\n",
    "    alist = []\n",
    "    if query_count < 10:\n",
    "        query_count += 1\n",
    "        for a in sp.artist_related_artists(artid)['artists']: # get, loop through related artists\n",
    "            gc = 0\n",
    "            if (followers == -1): # no need to count followers if not specified\n",
    "                for g in a['genres']:    \n",
    "                    if g in genres:\n",
    "                        gc += 1\n",
    "                if gc > 0 and ([item for item in alist if item[1] == a['id']] == []):\n",
    "                    alist.append((a['name'], a['id'], gc, a['followers']['total']))\n",
    "            else: # count followers\n",
    "                if (lessthan == True):\n",
    "                    if (a['followers']['total'] < followers):\n",
    "                        for g in a['genres']:    \n",
    "                            if g in genres:\n",
    "                                gc += 1\n",
    "                        if gc > 0 and ([item for item in alist if item[1] == a['id']] == []):\n",
    "                            alist.append((a['name'], a['id'], gc, a['followers']['total']))\n",
    "                elif (lessthan == False):\n",
    "                    if (a['followers']['total'] >= followers):\n",
    "                        for g in a['genres']:    \n",
    "                            if g in genres:\n",
    "                                gc += 1\n",
    "                        if gc > 0 and ([item for item in alist if item[1] == a['id']] == []):\n",
    "                            alist.append((a['name'], a['id'], gc, a['followers']['total']))\n",
    "                \n",
    "        return sorted(alist, key = custom_sort, reverse = True) # sorts by amount matched genres, more = better\n",
    "                    \n",
    "# used to faciliate recursive calls - \n",
    "# allows me to find the related artists in each level of separation from the root\n",
    "# before moving on to the root artist\n",
    "def ra_rec(lst, genres, followers, lessthan):\n",
    "    global query_count\n",
    "    lst2 = []\n",
    "    query_count += 1\n",
    "    for a in lst:\n",
    "        if query_count < 10:\n",
    "            lst2+=(ra_help(a[1], genres, followers, lessthan))\n",
    "    if query_count < 10:\n",
    "        lst2 += (ra_rec((sorted(lst2, key = custom_sort)), genres, followers, lessthan))    \n",
    "    \n",
    "    return sorted(lst2, key = custom_sort, reverse = True)\n",
    "\n",
    "# main function to be called\n",
    "def related_artists(artname='', artid='', genre='', followers=-1, lessthan = True, llen = -1):\n",
    "    if (artname == '' and artid == '' and genre == ''):\n",
    "        print('please include name, id, or genre')\n",
    "        return\n",
    "    else:\n",
    "        global query_count #counts spotify queries\n",
    "        query_count = 0\n",
    "        alist = []\n",
    "        if (artname != ''):\n",
    "            se = sp.search(q = artname, limit = 1, type = 'artist')\n",
    "            query_count += 1\n",
    "            print(\"related_artists search \" + str(query_count))\n",
    "            if (se['artists']['total'] > 0):\n",
    "                artist = se['artists']['items'][0]\n",
    "                artid = artist['id']\n",
    "                genres = artist['genres']\n",
    "        elif (artid != ''):\n",
    "            artist = sp.artist(artid)\n",
    "            genres = artist['genres']\n",
    "            \n",
    "        \n",
    "        for a in sp.artist_related_artists(artid)['artists']:\n",
    "            genres+=a['genres']\n",
    "            \n",
    "\n",
    "        lst = ra_help(artid, genres, followers, lessthan)\n",
    "        query_count += 1\n",
    "        print(\"related_artists ra_help \" + str(query_count))\n",
    "                \n",
    "        if query_count < 10:\n",
    "            lst+=(ra_rec(lst, genres, followers, lessthan))\n",
    "            \n",
    "    if llen > 0:\n",
    "        return sorted(list(set(lst)), key = custom_sort, reverse = True)[0:llen]\n",
    "    else:\n",
    "        return sorted(list(set(lst)), key = custom_sort, reverse = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Songkick Functions\n",
    "\n",
    "[Back to top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# function definitions\n",
    "\n",
    "# takes json string from songkick for an artist and makes points based on the results\n",
    "def make_points(json_str, artist):\n",
    "    df = pd.DataFrame(\n",
    "    {'Artist': [],\n",
    "     'Venue': [],\n",
    "     'City': [],\n",
    "     'State/Province': [],\n",
    "     'Country': [],\n",
    "     'Longitude': [],\n",
    "     'Latitude': []})\n",
    "\n",
    "    i = 0\n",
    "    \n",
    "    if (json_str['resultsPage']['totalEntries'] != 0):\n",
    "        for p in json_str['resultsPage']['results']['event']:\n",
    "            #     print(p['popularity'])\n",
    "            venue = p['venue']['displayName']\n",
    "            lng = p['location']['lng']\n",
    "            lat = p['location']['lat']\n",
    "            city = p['location']['city']\n",
    "            state = 'N/A'\n",
    "            csplit = city.split(',')\n",
    "            country = csplit[1]\n",
    "        \n",
    "            if (len(csplit) == 3): # handle Washington, DC\n",
    "                if not ('Washington' == csplit[0] and 'DC' == csplit[1]):\n",
    "                    city = csplit[0]\n",
    "                    state = csplit[1]\n",
    "                    country = csplit[2]\n",
    "                else:\n",
    "                    city = csplit[0] + ', ' + csplit[1]\n",
    "                    state = 'N/A'\n",
    "                    country = csplit[2].replace(' ', '')\n",
    "        \n",
    "            df.loc[i] = [artist] + [venue] + [city] + [state] + [country] + [lat] +[lng] #add to dataframe\n",
    "\n",
    "            i+=1\n",
    "            \n",
    "        #convert to gdf to plot\n",
    "        gdf = gpd.GeoDataFrame(\n",
    "            df, geometry=[Point(x, y) for y, x in zip(df['Longitude'], df['Latitude'])])\n",
    "\n",
    "        gdf2 = gdf\n",
    "        gdf2 = gdf2.drop(list(range(1, len(gdf)))) # start point\n",
    "        gdf3 = gdf\n",
    "        gdf3 = gdf3.drop(list(range(0, len(gdf)-1))) # end point\n",
    "    \n",
    "        return(gdf, gdf2, gdf3)\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "# finds the longest stretch of concerts for an artist, given a cutoff number of days, tr, that\n",
    "# each show must play within. this is defaulted to 7.\n",
    "def find_tour(json_str, artist, tr = 7, cutoff_yr = 2):\n",
    "    df = pd.DataFrame(\n",
    "    {'Artist': [],\n",
    "     'Venue': [],\n",
    "     'City': [],\n",
    "     'State/Province': [],\n",
    "     'Country': [],\n",
    "     'Longitude': [],\n",
    "     'Latitude': [],\n",
    "     't': []})\n",
    "\n",
    "    i = 0\n",
    "    \n",
    "    arr = []\n",
    "    \n",
    "    if (json_str['resultsPage']['totalEntries'] != 0):\n",
    "        for p in json_str['resultsPage']['results']['event']:\n",
    "            if 'US' in p['location']['city']:\n",
    "                venue = p['venue']['displayName']\n",
    "                lng = p['location']['lng']\n",
    "                lat = p['location']['lat']\n",
    "                city = p['location']['city']\n",
    "                state = 'N/A'\n",
    "                csplit = city.split(',')\n",
    "                country = csplit[1]\n",
    "        \n",
    "                if (len(csplit) == 3): # handle Washington, DC\n",
    "                    if not ('Washington' == csplit[0] and 'DC' == csplit[1]):\n",
    "                        city = csplit[0]\n",
    "                        state = csplit[1]\n",
    "                        country = csplit[2]\n",
    "                    else:\n",
    "                        city = csplit[0] + ', ' + csplit[1]\n",
    "                        state = city\n",
    "                        country = csplit[2].replace(' ', '')\n",
    "                    df.loc[i] = [artist] + [venue] + [city] + [state] + [country] + [lat] + [lng] + [p['start']['date']] # add to df\n",
    "            \n",
    "                i+=1\n",
    "            \n",
    "                if (len(p['location']['city'].split(',')) == 3): # making a list of dates to find longest tour\n",
    "                    d = p['start']['date'].split('-')\n",
    "                    arr.append(date(int(d[0]), int(d[1]), int(d[2])))\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "    l = [0,0]\n",
    "    first = 0\n",
    "    last = 0\n",
    "    \n",
    "    #finding the indices of the longest tour\n",
    "    for i in range(len(arr)-1):\n",
    "        if (arr[i] != -1 and arr[i+1] != -1):\n",
    "            if (((arr[i] - arr[i+1]).days > tr) or (i == len(arr)-2)):\n",
    "                last = i\n",
    "                if (last-first > l[1] - l[0]):\n",
    "                    l = [first, last]\n",
    "                first = i+1\n",
    "        else:\n",
    "            last = i\n",
    "            if (last-first > l[1] - l[0]):\n",
    "                l = [first, last]\n",
    "            first = i+1\n",
    "            \n",
    "#     print(l)\n",
    "    \n",
    "    df2 = pd.DataFrame(\n",
    "    {'Artist': [],\n",
    "     'Venue': [],\n",
    "     'City': [],\n",
    "     'State/Province': [],\n",
    "     'Country': [],\n",
    "     'Longitude': [],\n",
    "     'Latitude': [],\n",
    "     't': []})\n",
    "    \n",
    "    # returning geodataframe of longest tour\n",
    "    if (len(df) > 0):\n",
    "        for i in range(l[0], l[1]+1):\n",
    "            df2.loc[i] = df.loc[i]\n",
    "        \n",
    "        #convert to gdf to plot\n",
    "        gdf = gpd.GeoDataFrame(\n",
    "                df2, geometry=[Point(x, y) for y, x in zip(df2['Longitude'], df2['Latitude'])])\n",
    "\n",
    "        return gdf\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "# plots path of shows for artist\n",
    "def run_plot(req, aname):\n",
    "    gdfs = make_points(req.json(), aname)\n",
    "\n",
    "    points_gdf = gdfs[0]\n",
    "    print(points_gdf)\n",
    "    start_gdf = gdfs[1]\n",
    "    stop_gdf = gdfs[2]\n",
    "\n",
    "    #current us basemap\n",
    "    world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "\n",
    "    # fig, ax = plt.subplots(figsize=(15,15))\n",
    "    ax = world[world.continent == 'North America'].plot(\n",
    "#     ax = world.plot(\n",
    "        color='white', edgecolor='black')\n",
    "\n",
    "    ax.set_xlim(-130, -65)\n",
    "    ax.set_ylim(24, 50)\n",
    "\n",
    "    # We can now plot our GeoDataFrame.\n",
    "    points_gdf.plot(ax=ax, color='blue')\n",
    "\n",
    "    start_gdf.plot(ax=ax, color='green')\n",
    "    stop_gdf.plot(ax=ax, color='red')\n",
    "\n",
    "    points = []\n",
    "\n",
    "    linedf = pd.DataFrame(\n",
    "        {'Line': []})\n",
    "\n",
    "    for i in range(len(points_gdf)):\n",
    "        points.append(points_gdf.iloc[i].loc[\"geometry\"])\n",
    "\n",
    "    line = LineString(points)\n",
    "\n",
    "    def plot_line(ax, ob):\n",
    "        x, y = ob.xy\n",
    "        ax.plot(x, y, color='grey', alpha=0.7, linewidth=1, solid_capstyle='round', zorder=2)\n",
    "\n",
    "    plot_line(ax, line) # plot line of the show\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "# used to find the artist id on songkick\n",
    "def get_artist_id(artist_name):\n",
    "    json_str = requests.get(\"https://api.songkick.com/api/3.0/search/artists.json?apikey=\" + api_key + \"&query=\" + artist_name).json()\n",
    "    return (str(json_str['resultsPage']['results']['artist'][0]['id']) if json_str['resultsPage']['totalEntries'] != 0 else -1)         \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis Functions\n",
    "\n",
    "[Back to top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# this function generates many related artists, returns most recent events for each one, \n",
    "def compile_points(names = [], followers = -1, event_num=8):\n",
    "    if not (names == []):\n",
    "            artists = []\n",
    "            if followers == -1:   \n",
    "                for n in names:\n",
    "                    artists += related_artists(artname = n, llen = 10)\n",
    "            else: # check for followers\n",
    "                for n in names:\n",
    "                    artists += related_artists(artname = n, llen = 10, followers = followers)\n",
    "\n",
    "            nl = [] #list of names\n",
    "            for a in artists:\n",
    "                nl.append(a[0])\n",
    "            \n",
    "            nl = list(set(nl)) #only unique values\n",
    "            \n",
    "            gl = []\n",
    "            \n",
    "            for a in nl: # get points for each artist\n",
    "                an = get_artist_id(a.replace(' ', '+')) if not (a[0]+' ').isspace() else print('need artist!')\n",
    "    \n",
    "                if an != -1:\n",
    "                    req = requests.get(\"https://api.songkick.com/api/3.0/artists/\"+ an +\"/gigography.json?apikey=\"+ api_key + '&per_page='+str(event_num)+'&order=desc')\n",
    "                    gdfs = make_points(req.json(), a)\n",
    "                    if gdfs != -1:\n",
    "                        gl.append(gdfs[0])\n",
    "                \n",
    "            return gl\n",
    "    else:\n",
    "        return -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create basic stats for top cities, states/countries, and venues\n",
    "def basic_stats(gdfs, state = ''):    \n",
    "    rdf = gpd.GeoDataFrame(pd.concat(gdfs, ignore_index=True))\n",
    "    \n",
    "    # basic stats\n",
    "    venues = {}\n",
    "    cities = {}\n",
    "    countries_states = {}\n",
    "    \n",
    "    for index, row in rdf.iterrows():\n",
    "        if row[1] != 'Unknown venue':\n",
    "            print(row)\n",
    "            if row[1] not in venues:\n",
    "                venues[row[1]] = 1\n",
    "            else:\n",
    "                venues[row[1]] += 1\n",
    "          \n",
    "        if row[3] != 'N/A':\n",
    "            if (row[2] + ', ' + row[3][1:]) not in cities:\n",
    "                cities[(row[2] + ', ' + row[3][1:])] = 1 # add city\n",
    "            else:\n",
    "                cities[(row[2] + ', ' + row[3][1:])] += 1 # increment\n",
    "        else:\n",
    "            if (row[2] + ', ' + row[4]) not in cities:\n",
    "                cities[(row[2] + ', ' + row[4][1:])] = 1 # add city\n",
    "            else:\n",
    "                cities[(row[2] + ', ' + row[4][1:])] += 1 # increment\n",
    "            \n",
    "        if row[3] != 'N/A':\n",
    "            if (row[3][1:]) not in countries_states:\n",
    "                countries_states[row[3][1:]] = 1\n",
    "            else:\n",
    "                countries_states[row[3][1:]] += 1\n",
    "\n",
    "        \n",
    "        if (row[4][1:]) not in countries_states:\n",
    "            countries_states[row[4][1:]] = 1\n",
    "        else:\n",
    "            countries_states[row[4][1:]] += 1\n",
    "            \n",
    "    print('Top 5 venues:')\n",
    "    top = Counter(venues)\n",
    "    for i in top.most_common(5):\n",
    "        print(i[0] + ' ' + str(i[1]))\n",
    "        \n",
    "    print('\\nTop 5 cities:')\n",
    "    top = Counter(cities)\n",
    "    for i in top.most_common(5):\n",
    "        print(i[0] + ' ' + str(i[1]))\n",
    "        \n",
    "    print('\\nTop 5 countries:')\n",
    "    top = Counter(countries_states)\n",
    "    for i in top.most_common(5):\n",
    "        print(i[0] + ' ' + str(i[1]))\n",
    "        \n",
    "    return(venues)\n",
    "        \n",
    "    # end basic stats    \n",
    "\n",
    "# conducts morans i test on data and plots\n",
    "def autocorr(gdfs, state = ''):\n",
    "    rdf = gpd.GeoDataFrame(pd.concat(gdfs, ignore_index=True))\n",
    "\n",
    "    plt.figure(figsize=(10, 12))\n",
    "\n",
    "    world = ws\n",
    "    \n",
    "    showcount = [] # list that will be appened to the shapefile of states/countries\n",
    "    \n",
    "    # go through each country and find their amount of shows\n",
    "    for index, row in world.iterrows():\n",
    "        if row[1] == 'United States':\n",
    "            c = 'US'            \n",
    "        elif row[1] == 'United Kingdom':\n",
    "            c = 'UK'\n",
    "        else:\n",
    "            c = row[1]\n",
    "#             print(c)\n",
    "        \n",
    "        if c in countries_states:\n",
    "            showcount.append(countries_states[c])\n",
    "        else:\n",
    "            showcount.append(0)\n",
    "        \n",
    "    world[\"ShowCount\"] = showcount #make new column\n",
    "\n",
    "    for index, row in ws.iterrows():\n",
    "        if row[1] == 'United States':\n",
    "            world.drop(index, inplace=True)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(15,15)) #plot\n",
    "    world.plot(\"ShowCount\", ax=ax)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # morans i\n",
    "\n",
    "    qW = Queen.from_dataframe(world)\n",
    "    \n",
    "    qW.silent_island_warning = True\n",
    "\n",
    "    qW.transform = 'r'\n",
    "\n",
    "    #moran\n",
    "    moran_sc = esda.moran.Moran(world[['ShowCount']], qW)\n",
    "\n",
    "    #lisa\n",
    "    lisa_sc = esda.Moran_Local(world[\"ShowCount\"], qW)\n",
    "\n",
    "    print(str(moran_sc.I) + \", \" + str(moran_sc.p_sim))\n",
    "    \n",
    "    from pysal.viz.splot import esda as esdaplot\n",
    "    esdaplot.plot_local_autocorrelation(lisa_sc, world, \"ShowCount\")\n",
    "\n",
    "    plt.show()    \n",
    "    \n",
    "def basic_analysis(gdfs, state = ''): # both functions together\n",
    "    rdf = gpd.GeoDataFrame(pd.concat(gdfs, ignore_index=True))\n",
    "    basic_stats(gdfs)\n",
    "    autocorr(gdfs)\n",
    "    \n",
    "# counts amount of shows by venue, for folium mapping and optimal tour path\n",
    "def venue_count(gdfs, usonly = True):    \n",
    "    rdf = gpd.GeoDataFrame(pd.concat(gdfs, ignore_index=True))\n",
    "    \n",
    "    venues = {}\n",
    "    \n",
    "    if (usonly == True):\n",
    "        for index, row in rdf.iterrows():\n",
    "            if row[1] != 'Unknown venue':\n",
    "                if (row[4].replace(' ', '') == 'US'): \n",
    "                    if row[1] not in venues.keys():\n",
    "                        venues[row[1]] = [(row[5],row[6], row[2], row[3].replace(' ', '')), 1]\n",
    "                    else:\n",
    "                        venues[row[1]][1] += 1\n",
    "        \n",
    "    return(venues)\n",
    "\n",
    "# gets tracts with certain demographic and socioeconomic data for venue locations\n",
    "def get_tracts(vens):\n",
    "    tracts = {}\n",
    "    \n",
    "    for k,v in vens.items():\n",
    "        x = float(v[0][1])\n",
    "        y = float(v[0][0])\n",
    "        r = ''\n",
    "        try:\n",
    "            r = censusgeocode.coordinates(x=x, y=y) # finds tract\n",
    "        except:\n",
    "            print('censusgeocode error')\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            r = r['2010 Census Blocks']\n",
    "            st = r[0]['STATE']\n",
    "            co = r[0]['COUNTY']\n",
    "            tr = r[0]['TRACT']\n",
    "            print(st + co + tr)\n",
    "            \n",
    "            #retrieving data from census\n",
    "            b = cen.acs5.state_county_tract('B02001_002E,B02001_001E,B01002_001E,B19013_001E', st, co, tr)\n",
    "            b2 = cen.acs5.state_county_tract('B02001_003E', st, co, tr)\n",
    "\n",
    "            ftr = st + co + tr # full tract code\n",
    "            if (ftr not in tracts.keys()):\n",
    "                # factors of significance being calculated\n",
    "                tracts[ftr] = {'Non-white population percentage': -1,\n",
    "                'Black population percentage': -1,\n",
    "                'Median age': -1,\n",
    "                'Median household income': -1,\n",
    "#                 'Nonfamily households percentage': -1,\n",
    "                'Count': -1}\n",
    "                # non-white/total pop\n",
    "                tracts[ftr]['Non-white population percentage'] = (1 - b[0]['B02001_002E']/b[0]['B02001_001E'])\n",
    "                # black/total\n",
    "                tracts[ftr]['Black population percentage'] = b2[0]['B02001_003E']/b[0]['B02001_001E']\n",
    "                tracts[ftr]['Median age'] = b[0]['B01002_001E']\n",
    "                tracts[ftr]['Median household income'] = b[0]['B19013_001E']\n",
    "#                 tracts[ftr]['Nonfamily households percentage'] = b2[0]['B11001_007E']/b2[0]['B11001_001E']\n",
    "                tracts[ftr]['Count'] = v[1] # amount of shows in cenus tract\n",
    "            else:\n",
    "                tracts[ftr]['Count'] += v[1] # add to shows\n",
    "        except KeyboardInterrupt:\n",
    "            raise\n",
    "        except:\n",
    "            print('some other error')\n",
    "            \n",
    "    return tracts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computes linear regression with tract information\n",
    "def tract_reg(tr, demo='non-white'):\n",
    "#     print(tr)\n",
    "\n",
    "    # finding size of 2D list\n",
    "    height = len(tr)\n",
    "    width = len(next(iter(tr.values())))\n",
    "    for k,vl in tr.items():\n",
    "        v = list(vl.values())\n",
    "        for i in range(width):\n",
    "            if v[i] == -1:\n",
    "#                 print(i)\n",
    "                height = height - 1\n",
    "                break\n",
    "\n",
    "    print(height)\n",
    "    print(width)\n",
    "\n",
    "    # 2D list, each row is tract and columns are different values for census factors \n",
    "    arrr = [[0 for x in range(width-1)] for y in range(height)] \n",
    "\n",
    "    c = []\n",
    "\n",
    "    i = 0\n",
    "    \n",
    "    # populating the 2D list with tracts and info, as long as no errors in its info\n",
    "    for k,vl in tr.items():\n",
    "        v = list(vl.values())\n",
    "\n",
    "        con = False # if true, continue\n",
    "        for j in range(width-1):\n",
    "            if v[j] == -1:\n",
    "                con = True\n",
    "\n",
    "        if (con==True):\n",
    "            continue\n",
    "\n",
    "        c.append(v[width-1])\n",
    "        for j in range(width-1):\n",
    "            arrr[i][j] = v[j]\n",
    "        i+=1\n",
    "    \n",
    "    # whether to use non-white or black percentage\n",
    "    if (demo == 'black'):\n",
    "        for row in arrr:\n",
    "            del row[0]\n",
    "    else:\n",
    "        for row in arrr:\n",
    "            del row[1]\n",
    "        \n",
    "    return statsmodels.regression.linear_model.OLS(c, arrr).fit().summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def tract_stats(names, followers, demo): # calls functions to do tract regression\n",
    "    points = compile_points(names, followers = followers)\n",
    "    tracts = get_tracts(venue_count(points))\n",
    "    print(tract_reg(tracts, demo=demo))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "# # print(arrr)\n",
    "# print(len(c))\n",
    "# statsmodels.regression.linear_model.OLS(c, arrr).fit().summary()\n",
    "# # print(statsmodels.)\n",
    "# X = numpy.array(arrr)\n",
    "# # print(X)\n",
    "# vif = [variance_inflation_factor(X, i) for i in range(X.shape[1])]\n",
    "# print(vif)\n",
    "# # statsmodels.regression.linear_model.OLS(c, arrr).fit().summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# req_input()\n",
    "\n",
    "#travis scott, 2018-10-31, 2018-12-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# this function generates many related artists, returns longest tours for each one, \n",
    "def compile_tours(names = [], followers = -1, lessthan = True):\n",
    "    if (names != [] and isinstance(names, list)):\n",
    "            artists = []\n",
    "            \n",
    "            # get 10 related artists for each name\n",
    "            if followers == -1:   \n",
    "                for n in names:\n",
    "                    artists += related_artists(artname = n, llen = 10)\n",
    "            else:\n",
    "                for n in names:\n",
    "                    artists += related_artists(artname = n, llen = 10, followers = followers)\n",
    "\n",
    "            print(artists)\n",
    "            nl = []\n",
    "            for a in artists:\n",
    "                nl.append(a[0])\n",
    "            \n",
    "            nl = list(set(nl)) # unique list of names\n",
    "            \n",
    "            print(len(nl))\n",
    "            \n",
    "            gl = []\n",
    "            \n",
    "            # for each artist, get show data and find longest tour\n",
    "            for a in nl:\n",
    "                an = get_artist_id(a.replace(' ', '+')) if not (a[0]+' ').isspace() else print('need artist!')\n",
    "    \n",
    "                if an != -1:\n",
    "                    req = requests.get(\"https://api.songkick.com/api/3.0/artists/\"+ an +\"/gigography.json?apikey=\"+ api_key + '&per_page=50&order=desc')\n",
    "#             print(\"https://api.songkick.com/api/3.0/artists/\"+ an +\"/gigography.json?apikey=\"+ api_key + '&per_page=20&order=desc')\n",
    "                    g = find_tour(req.json(), a) # find tour\n",
    "                    if g is not int:\n",
    "                        gl.append(g)\n",
    "            \n",
    "            return gl\n",
    "    else:\n",
    "        return -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# just plots tours given multiple artists' tours\n",
    "def plot_all_tours(ts):\n",
    "    m = folium.Map(location=[40, -95], zoom_start=4)\n",
    "\n",
    "    colors = ['blue', 'purple', 'orange', 'darkred', 'lightred', 'beige', 'darkblue', 'darkgreen', 'cadetblue', 'darkpurple', 'white', 'pink', 'lightblue', 'lightgreen']\n",
    "\n",
    "    cc = -1\n",
    "    \n",
    "    # plot each tour\n",
    "    for x in ts:\n",
    "        if not isinstance(x, int) and len(x) != 0:\n",
    "            if (cc!=len(colors)-1):\n",
    "                cc += 1\n",
    "            else:\n",
    "                cc = 0\n",
    "    \n",
    "            points = []\n",
    "\n",
    "            for i, row in x.iterrows():\n",
    "                tooltip = 'Artist: '+ str(row[0]) + '- City: ' + str(row[2]) + ', ' + str(row[3])\n",
    "\n",
    "                points.append((row[5], row[6]))\n",
    "\n",
    "                folium.Circle([row[5], row[6]], radius = 8, color = colors[cc], fill = True, weight = 5, popup='<i></i>', tooltip=tooltip).add_to(m)\n",
    "\n",
    "            folium.PolyLine(points, color=colors[cc], weight=2.5, opacity=1).add_to(m)\n",
    "            \n",
    "    return m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorizes cities by the amount of shows they have, finds path of cities to tour\n",
    "def optimal_path(ts):\n",
    "    avg = 0\n",
    "    maxm = 0\n",
    "    cities = {}\n",
    "    #     print(len(list))\n",
    "    \n",
    "    #tallying show counts by city\n",
    "    for t in ts:\n",
    "        if not isinstance(t, int):\n",
    "            for i,row in t.iterrows():\n",
    "                city = str(row[2]) + ', ' + str(row[3]) + ', ' + str(row[4])\n",
    "                if city not in cities.keys():\n",
    "                    cities[city] = [(row[5], row[6]), 1]\n",
    "                else:\n",
    "                    cities[city][1] += 1\n",
    "\n",
    "    # sorting by show counts\n",
    "    lst = sorted(cities.items(), key = \n",
    "             lambda kv:(kv[1][1], kv[0]), reverse=True)\n",
    "\n",
    "    \n",
    "    maxm = lst[0][1][1] #maximum shows\n",
    "    sl = [] # list to find standard deviation\n",
    "    for i in lst:\n",
    "        avg += i[1][1]\n",
    "        sl.append(i[1][1])\n",
    "\n",
    "    sd = statistics.stdev(sl) # standard deviation\n",
    "\n",
    "    avg = avg/len(lst) # average\n",
    "\n",
    "    # lists for different classifications\n",
    "    green = []\n",
    "    lg = []\n",
    "    yellow = []\n",
    "    red = []\n",
    "\n",
    "    # classifying\n",
    "    for i in lst:\n",
    "        count = i[1][1]\n",
    "        if (count >= avg + sd*1.5):\n",
    "            green.append(i[1][0])\n",
    "        elif (count >= avg):\n",
    "            lg.append(i[1][0])\n",
    "        elif (count >= avg - sd/2):\n",
    "            yellow.append(i[1][0])\n",
    "        else:\n",
    "            red.append(i[1][0])\n",
    "\n",
    "    final_points = green # start with best points\n",
    "\n",
    "    # distance between points\n",
    "    def dist(x,y):\n",
    "        return math.hypot(y[0]-x[0],y[1]-x[1])\n",
    "\n",
    "    # creating path from point to point in final_points\n",
    "    paths = [ p for p in it.permutations(final_points) ]\n",
    "    path_distances = [ sum(map(lambda x: dist(x[0],x[1]),zip(p[:-1],p[1:]))) for p in paths ]\n",
    "    min_index = numpy.argmin(path_distances)\n",
    "\n",
    "    print(str(paths[min_index]) + ' ' + str(path_distances[min_index]))\n",
    "\n",
    "    final_path = []\n",
    "\n",
    "    # add created paths to final_path\n",
    "    for i in paths[min_index]:\n",
    "        final_path.append(i)\n",
    "\n",
    "    print(final_path)\n",
    "\n",
    "    # add to final_path if within a certain cutoff distance (std)\n",
    "    def add_fp(fp, l, std):\n",
    "        i = 0\n",
    "        while (i < len(l)):\n",
    "            if (l[i] not in fp):\n",
    "                for j in range(len(fp)-1):\n",
    "                    if ((dist(fp[j], l[i]) + dist(l[i], fp[j+1])) < (std*dist(fp[j], fp[j+1]))):\n",
    "                        if (l[i] not in fp):\n",
    "                            fp.insert(j+1, l[i])\n",
    "                            print(l[i])\n",
    "                            i = -1\n",
    "                        continue\n",
    "            i+=1\n",
    "\n",
    "        return fp\n",
    "\n",
    "    final_path = add_fp(final_path, lg, 1.5)\n",
    "    final_path = add_fp(final_path, yellow, 1.2)\n",
    "    final_path = add_fp(final_path, red, 1.05)\n",
    "\n",
    "    print(final_path)\n",
    "\n",
    "    m = folium.Map(location=[40, -95], zoom_start=4) # init folium map instance\n",
    "\n",
    "    count = 0 # count of points to check\n",
    "    for k, v in lst:\n",
    "        color = ''\n",
    "        if (v[0] in green):\n",
    "            count+=1\n",
    "            color = 'green'\n",
    "        elif (v[0] in lg):\n",
    "            count+=1\n",
    "            color = 'lightgreen'\n",
    "        elif (v[0] in yellow):\n",
    "            count+=1\n",
    "            color = 'yellow'\n",
    "        elif (v[0] in red):\n",
    "            count+=1\n",
    "            color = 'red'\n",
    "        else:\n",
    "            print('oops')\n",
    "                \n",
    "        # add point to map\n",
    "        tooltip = 'City: ' + str(k) + ' - Count: ' + str(v[1])\n",
    "        folium.Circle([v[0][0], v[0][1]], radius = 8, color = color, fill = True, weight = 5, popup='<i></i>', tooltip=tooltip).add_to(m)\n",
    "\n",
    "    # create line that represents final path from point to point\n",
    "    folium.PolyLine(final_path, color='blue', weight=1, opacity=1.5).add_to(m)\n",
    "  \n",
    "    return m\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# used to find the artist id on songkick\n",
    "def get_artist_id(artist_name):\n",
    "    json_str = requests.get(\"https://api.songkick.com/api/3.0/search/artists.json?apikey=\" + api_key + \"&query=\" + artist_name).json()\n",
    "    return (str(json_str['resultsPage']['results']['artist'][0]['id']) if json_str['resultsPage']['totalEntries'] != 0 else -1)\n",
    "\n",
    "# function for interface for taking input\n",
    "def req_input():\n",
    "    print(\"Welcome\")\n",
    "    while (True):\n",
    "        past = True\n",
    "        is_search = True\n",
    "        \n",
    "        cmd = input(\"Search (0) or functions (1)\")\n",
    "        \n",
    "        if cmd == 1:\n",
    "            is_search = False\n",
    "            \n",
    "        if (is_search == False):\n",
    "            cmd = input('''\n",
    "            Basic analysis of the concerts for artist and their related artists? (0)\\n\n",
    "            Plot points for an artist, and their related artists? (1)\\n\n",
    "            Find optimal path for an artist? (2)\\n\n",
    "            Tract stats? (3)\n",
    "            ''')\n",
    "            \n",
    "            if (cmd == 0):\n",
    "                cmd = input(\"Type artist name: \")\n",
    "                basic_analysis(cmd)\n",
    "            elif (cmd == 1):\n",
    "                cmd = input(\"Type artist name: \")\n",
    "                plot_all_tours(compile_tours[cmd])\n",
    "            elif (cmd == 2):\n",
    "                cmd = input(\"Type artist name: \")\n",
    "                optimal_path(compile_tours[cmd])\n",
    "            elif (cmd == 3):\n",
    "                cmd = input(\"Type artist name: \")\n",
    "                tract_stats([cmd])\n",
    "        else:\n",
    "            cmd = input(\"Venue search (0) or event search (1)?\")\n",
    "        \n",
    "            past = True\n",
    "            is_venue = True\n",
    "            if (cmd == 1):\n",
    "                is_venue = False\n",
    "\n",
    "            if (is_venue == False):\n",
    "                cmd = input(\"Past events (0), upcoming events (1): \")\n",
    "\n",
    "                if (cmd == 1):\n",
    "                    past = False\n",
    "\n",
    "                cmd = input(\"Please type the parameters: [artist_name, min_date, max_date.] Separate with commas.\"\n",
    "                           + \"\\nIf no input, just add a comma and skip.\\n\")\n",
    "\n",
    "                if (cmd == 'quit'):\n",
    "                    return\n",
    "\n",
    "                cs = cmd.split(',')\n",
    "                an = get_artist_id(cs[0].replace(' ', '+')) if not (cs[0]+' ').isspace() else print('need artist!')\n",
    "                if (cs[0]+' ').isspace():\n",
    "                    continue\n",
    "                mind = \"&min_date=\" + cs[1].replace(' ', '') if (re.search(\"\\d{4}-\\d{2}-\\d{2}\", cs[1])) else ''\n",
    "                maxd = \"&max_date=\" + cs[2].replace(' ', '') if (re.search(\"\\d{4}-\\d{2}-\\d{2}\", cs[2])) else ''\n",
    "\n",
    "                if (past == True):\n",
    "                    r = requests.get(\"https://api.songkick.com/api/3.0/artists/\"+ an +\"/gigography.json?apikey=\"+ api_key \n",
    "                                  + mind + maxd)\n",
    "                    run_plot(r, cs[0])\n",
    "                else:\n",
    "                    r = requests.get(\"https://api.songkick.com/api/3.0/events.json?apikey=\"+ api_key \n",
    "                        + an + loc + mind + maxd)\n",
    "                    print(r.json())\n",
    "                    run_plot(r, cs[0])\n",
    "            else:\n",
    "                cmd = input(\"Past venues (0), upcoming venues (1): \")\n",
    "\n",
    "                if (cmd == 1):\n",
    "                    past = False\n",
    "\n",
    "            cmd = input(\"Please type the parameters: [artist_name, min_date, max_date.] Separate with commas.\"\n",
    "                       + \"\\nIf no input, just add a comma and skip.\\n\")\n",
    "\n",
    "            if (cmd == 'quit'):\n",
    "                return\n",
    "\n",
    "            cs = cmd.split(',')\n",
    "            an = get_artist_id(cs[0].replace(' ', '+')) if not (cs[0]+' ').isspace() else print('need artist!')\n",
    "            if (cs[0]+' ').isspace():\n",
    "                continue\n",
    "            mind = \"&min_date=\" + cs[1].replace(' ', '') if (re.search(\"\\d{4}-\\d{2}-\\d{2}\", cs[1])) else ''\n",
    "            maxd = \"&max_date=\" + cs[2].replace(' ', '') if (re.search(\"\\d{4}-\\d{2}-\\d{2}\", cs[2])) else ''\n",
    "\n",
    "            if (past == True):\n",
    "                r = requests.get(\"https://api.songkick.com/api/3.0/artists/\"+ an +\"/gigography.json?apikey=\"+ api_key \n",
    "                                  + mind + maxd)\n",
    "                run_plot(r, cs[0])\n",
    "            else:\n",
    "                r = requests.get(\"https://api.songkick.com/api/3.0/events.json?apikey=\"+ api_key \n",
    "                    + an + loc + mind + maxd)\n",
    "                print(r.json())\n",
    "                run_plot(r, cs[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis (look at other file for this section)\n",
    "\n",
    "[Back to top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three genres: Hip-hop, Rock, Country and Four regions each: Midwest, East, West, South\n",
    "\n",
    "Each pair of genre/region uses four or five artists that are from that area and under that genre.\n",
    "\n",
    "These artists are used as the root artists to find related artists to get a sample of performance data.\n",
    "\n",
    "Under each genre/region pair, there is:\n",
    "* a regression done on the tracts the venues are found in\n",
    "* plot of each artist's longest tour path from their past 50 shows\n",
    "* a plot of the optimal path an artist would take with color coded points to signify the quality of each stop\n",
    "    * Green: Shows > average + 1.5*sd\n",
    "    * light green: Shows > average\n",
    "    * Yellow: Shows > average - sd/2\n",
    "    * red: everything else "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hip-hop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x1: (Black population)/(Total Population)\n",
    "\n",
    "x2: Median Age\n",
    "\n",
    "x3: Median Household Income"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Midwest (https://djbooth.net/features/2015-11-03-next-up-in-the-midwest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 922,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yo\n",
      "related_artists search 1\n",
      "related_artists ra_help 3\n",
      "56\n",
      "28\n",
      "related_artists search 1\n",
      "related_artists ra_help 3\n",
      "110\n",
      "78\n",
      "related_artists search 1\n",
      "related_artists ra_help 3\n",
      "65\n",
      "18\n",
      "related_artists search 1\n",
      "related_artists ra_help 3\n",
      "67\n",
      "23\n",
      "25017353101\n",
      "some other error\n",
      "censusgeocode error\n",
      "39049003200\n",
      "29095015800\n",
      "08031003701\n",
      "censusgeocode error\n",
      "censusgeocode error\n",
      "censusgeocode error\n",
      "censusgeocode error\n",
      "53033008600\n",
      "17031330100\n",
      "censusgeocode error\n",
      "censusgeocode error\n",
      "censusgeocode error\n",
      "37183052602\n",
      "censusgeocode error\n",
      "censusgeocode error\n",
      "36047044900\n",
      "13121000500\n",
      "censusgeocode error\n",
      "censusgeocode error\n",
      "06037700501\n",
      "48113020400\n",
      "censusgeocode error\n",
      "censusgeocode error\n",
      "13121000500\n",
      "censusgeocode error\n",
      "17031061100\n",
      "09003500100\n",
      "48113020400\n",
      "06073002201\n",
      "censusgeocode error\n",
      "censusgeocode error\n",
      "06083000900\n",
      "06037208502\n",
      "censusgeocode error\n",
      "censusgeocode error\n",
      "53033010300\n",
      "08031001701\n",
      "04013218300\n",
      "censusgeocode error\n",
      "13121011900\n",
      "censusgeocode error\n",
      "censusgeocode error\n",
      "censusgeocode error\n",
      "48201310100\n",
      "censusgeocode error\n",
      "censusgeocode error\n",
      "censusgeocode error\n",
      "censusgeocode error\n",
      "16027021100\n",
      "26163531900\n",
      "26163520800\n",
      "47157003400\n",
      "06037576001\n",
      "48453001100\n",
      "48029190200\n",
      "censusgeocode error\n",
      "censusgeocode error\n",
      "censusgeocode error\n",
      "25025000803\n",
      "16001000100\n",
      "censusgeocode error\n",
      "16019970501\n",
      "censusgeocode error\n",
      "30111000402\n",
      "46103010200\n",
      "38017000700\n",
      "27053106200\n",
      "censusgeocode error\n",
      "06075020100\n",
      "censusgeocode error\n",
      "censusgeocode error\n",
      "censusgeocode error\n",
      "11001010200\n",
      "censusgeocode error\n",
      "48113020400\n",
      "53033004900\n",
      "06037212900\n",
      "55079007700\n",
      "55079014900\n",
      "06059074106\n",
      "06073005300\n",
      "13121003500\n",
      "06075022702\n",
      "censusgeocode error\n",
      "06087101000\n",
      "48201310900\n",
      "48453001100\n",
      "censusgeocode error\n",
      "32031002104\n",
      "06073005300\n",
      "35001002100\n",
      "04013421202\n",
      "censusgeocode error\n",
      "censusgeocode error\n",
      "12095018900\n",
      "50\n",
      "5\n",
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.786\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.772\n",
      "Method:                 Least Squares   F-statistic:                              57.47\n",
      "Date:                Tue, 10 Dec 2019   Prob (F-statistic):                    9.32e-16\n",
      "Time:                        18:37:20   Log-Likelihood:                         -50.004\n",
      "No. Observations:                  50   AIC:                                      106.0\n",
      "Df Residuals:                      47   BIC:                                      111.7\n",
      "Df Model:                           3                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             0.0172      0.507      0.034      0.973      -1.003       1.037\n",
      "x2             0.0272      0.007      4.128      0.000       0.014       0.040\n",
      "x3          5.296e-06    3.2e-06      1.657      0.104   -1.13e-06    1.17e-05\n",
      "==============================================================================\n",
      "Omnibus:                       30.580   Durbin-Watson:                   1.252\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               59.508\n",
      "Skew:                           1.886   Prob(JB):                     1.20e-13\n",
      "Kurtosis:                       6.786   Cond. No.                     3.39e+05\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 3.39e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "tract_stats(names = ['pat app', 'supakaine', 'Kweku Collins', 'IshDARR'], followers = 50000, demo = 'black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Rock:\n",
    "    \n",
    "    West: names = ['The Bonfire Set', 'Elephant Rifle', 'LO MOON', 'PINKY PINKY', 'My Goodness']\n",
    "    East: names = ['Air Traffic Controller', 'Big Thief', 'J and The 9s', 'Charly Bliss', 'Hop Along']\n",
    "    Midwest: names = ['Hemmingbirds', 'The Accidentals', 'The Cactus Blossoms', 'Chicken Wire Empire', 'Rodeo Ruby Love']\n",
    "    South: names = ['Savoy Motel', 'Ringo Deathstarr', 'Gull', 'Shadowgraphs', 'Young Mister']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yo\n",
      "related_artists search 1\n",
      "related_artists ra_help 3\n",
      "0\n",
      "0\n",
      "related_artists search 1\n",
      "related_artists ra_help 3\n",
      "128\n",
      "72\n",
      "related_artists search 1\n",
      "related_artists ra_help 3\n",
      "93\n",
      "46\n",
      "related_artists search 1\n",
      "related_artists ra_help 3\n",
      "0\n",
      "0\n",
      "related_artists search 1\n",
      "related_artists ra_help 3\n",
      "96\n",
      "51\n",
      "[('Big Black', '5EYkvHZuGM3pwU3DZUrrZ3', 14, 41236), ('The Jesus Lizard', '6r26MaDr8bqNALjXgYPXMa', 14, 46910), ('Wipers', '0sTTw3dw3EA0c7NaZnrJd2', 14, 28922), ('Unwound', '4YjpqCSDD7zwMQgPYJMqb0', 13, 28694), ('Mission Of Burma', '5UMQV83wwZCCvRSQCVjZw6', 13, 37760), ('Shellac', '6I8R5MFTlez7rHCsH4cx0u', 12, 48145), ('Flipper', '20VDXslLsXlLgSF765m1Ug', 9, 22700), ('Lightning Bolt', '2og3FOCLYXT9H7IYE6QPUq', 9, 44518), ('Brainiac', '0No2Og1pAwgw0eMmY6PPVP', 9, 8969), ('Scratch Acid', '219VCiRViG60EbPiocSWJp', 8, 16437), ('VHS Collection', '2Nvaq4y2ygxIqfwXyz0HeH', 7, 43655), ('Talos', '5pdzKTGQAcRcxDOfN4mXSc', 7, 38886), ('Mating Ritual', '4ZeB1hzT2mSZrf7wszOqHs', 6, 19305), ('courtship.', '2OK16hAFRHoJiFZKeZe8A8', 5, 30611), ('Zola Blood', '3oxkIoEAyXXQlLTZXlffLJ', 5, 37384), ('Handsome Ghost', '3IaqL9bsZtYJkqNLiovVho', 5, 45202), ('Arctic Lake', '0IEPb9ily3E5IAYMSkwtQ6', 5, 19008), ('Bay Ledges', '7FhRUp59cBzPaxobsRY1Nc', 4, 14955), ('Fractures', '7sjRnhONmeFL1tmlUvdq70', 3, 27465), ('Future Generations', '3wKj5PmSpnrtz9n9hG2QCA', 3, 14320), ('The Parlor Mob', '1U4d20oJAq9aLa2mhDGwVV', 6, 33795), ('Dead Man Winter', '3S3wKbKQc3QdCKExlBBzxw', 6, 14026), ('Goodbye June', '1l9I7G8J8AnMScWQwlNJ4M', 6, 49164), ('The Felice Brothers', '4Ajgo7nAsTzjSFymIfBjZ1', 6, 44772), ('Middle Brother', '5au2vhHl8DViD9PUxUZBTb', 6, 35206), ('Anders Osborne', '3WUUtA45g7X0jbeywZz888', 5, 30892), ('Futurebirds', '4Ait1vX2ZaWPrkua8Z664O', 5, 22676), ('The Stone Foxes', '40N10exWtaCVUtBMftQn3t', 5, 43236), ('Phil Cook', '3pqmhj6H08f5rGsnVroz9E', 4, 11199), ('The Pack a.d.', '2gbOUPIhea9nrCmAeZBgpo', 4, 25247)]\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "tours = compile_tours(names = ['The Bonfire Set', 'Elephant Rifle', 'LO MOON', 'PINKY PINKY', 'My Goodness'], followers = 50000)\n",
    "\n",
    "# plot_all_tours(tours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_path(tours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
